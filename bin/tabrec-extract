#!/usr/bin/env python3
"""
Usage:
  tabrec-extract [options] <fields_path> <filename>...

Options:
  -d, --delimiter DELIM  Set the delimiter (default: tab)
  -s, --subtypecol COL   The column containing the record subtype
                         (default: any column may contain the subtype value)
  -f, --fieldnames FN    A string containing record type, a colon, and a
                         comma-separated list of names of the fields
                         after the record type, in order.
                         Multiple such strings may be given, separated by
                         a semicolon. E.g. "A:foo,bar;B:baz,quux"
                         (default: none; only field numbers and tag names are used)
  -f --filewise          Handle each input file separately (default: concatenate them)
  -h --help              Show this screen.
  -V --version           Show version.

Arguments:
  <fields_path>    address of the fields to extract
  <filename>...       file(s) to use; if not given, the standard input
                      is used if the input is a pipe, otherwise all tsv files
                      in the current directory are used
"""

import csv
import sys
import docopt
import glob
import os
from tabrec.path import parse_fields_path, extract_fields, parse_fieldnames

def apply_fieldnames_to_extracted(extracted, rt_fieldnames):
  k = list(extracted.keys())
  for fn in k:
    if isinstance(fn, int):
      extracted[rt_fieldnames[fn - 1]] = extracted.pop(fn)
  return extracted

def process_table(filenames, fields_path, subtype_column, indent, delimiter,
                  fieldnames):
  record_type_column = 0
  for filename in filenames:
    with open(filename, 'r') as file:
      reader = csv.reader(file, delimiter=delimiter)
      lineno = 0
      for row in reader:
        lineno += 1
        extracted = extract_fields(row, fields_path, subtype_column)
        rt = row[record_type_column]
        if extracted:
          if fieldnames and rt in fieldnames:
            extracted = apply_fieldnames_to_extracted(extracted,
                fieldnames[rt])
          indent_str = ' ' * indent
          print("{}{}  {}  {}".format(indent_str, lineno, rt, extracted))

def parse_colnum(arg, minimum, default, name):
  if not arg:
    return default
  else:
    if not all(val.isdigit() for val in arg):
      sys.stderr.write(\
          f"Error: {name} column number must be an unsigned integer\n")
      sys.stderr.write(f"Found: {arg}\n")
      exit(1)
    colnum = int(arg)
    if colnum < minimum:
      sys.stderr.write(f"Error: {name} column number must be >= {minimum}\n")
      sys.stderr.write(f"Found: {arg}\n")
      exit(1)
    return colnum - 1

def parse_files(arg):
  if arg:
    for file in arg:
      if not os.path.isfile(file):
        sys.stderr.write("Error: file not found: {}\n".format(file))
        exit(1)
    return arg
  else:
    # check if there is an incoming pipe
    if not sys.stdin.isatty():
      return [sys.stdin]
    else:
      # all tsv files in the directory
      return glob.glob('*.tsv')

def main():
  args = docopt.docopt(__doc__, version='1.0')
  subtype_colnum = parse_colnum(args['--subtypecol'], 2, None, 'subtype')
  filenames = parse_files(args['<filename>'])
  delimiter = args['--delimiter'] if args['--delimiter'] else '\t'
  try:
    fieldnames = parse_fieldnames(args['--fieldnames'])
    fields_path = parse_fields_path(args['<fields_path>'], fieldnames)
  except ValueError as e:
    sys.stderr.write("Error: {}\n".format(e))
    exit(1)
  if args['--filewise']:
    for filename in filenames:
      print("File: {}".format(filename))
      process_table([filename], fields_path, subtype_colnum, 2, delimiter,
          fieldnames)
  else:
    process_table(filenames, fields_path, subtype_colnum, 0, delimiter,
        fieldnames)

if __name__ == '__main__':
  main()
